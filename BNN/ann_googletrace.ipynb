{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>numberOfTaskIndex</th>\n",
       "      <th>numberOfMachineId</th>\n",
       "      <th>meanCPUUsage</th>\n",
       "      <th>canonical_memory_usage</th>\n",
       "      <th>AssignMem</th>\n",
       "      <th>unmapped_cache_usage</th>\n",
       "      <th>page_cache_usage</th>\n",
       "      <th>max_mem_usage</th>\n",
       "      <th>mean_diskIO_time</th>\n",
       "      <th>mean_local_disk_space</th>\n",
       "      <th>max_cpu_usage</th>\n",
       "      <th>max_disk_io_time</th>\n",
       "      <th>cpi</th>\n",
       "      <th>mai</th>\n",
       "      <th>sampling_portion</th>\n",
       "      <th>agg_type</th>\n",
       "      <th>sampled_cpu_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.668381</td>\n",
       "      <td>0.158746</td>\n",
       "      <td>0.351781</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>5.33933</td>\n",
       "      <td>0.761954</td>\n",
       "      <td>182.528000</td>\n",
       "      <td>0.388110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>0.668381</td>\n",
       "      <td>0.158746</td>\n",
       "      <td>0.351781</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>5.33933</td>\n",
       "      <td>0.761954</td>\n",
       "      <td>182.528000</td>\n",
       "      <td>0.388110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.739129</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.196537</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>5.17264</td>\n",
       "      <td>0.336054</td>\n",
       "      <td>187.960999</td>\n",
       "      <td>0.396634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1140.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.739129</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.196537</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>5.17264</td>\n",
       "      <td>0.336054</td>\n",
       "      <td>187.960999</td>\n",
       "      <td>0.396634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1320.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.558318</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>0.362985</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>0.189972</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>4.69266</td>\n",
       "      <td>0.093905</td>\n",
       "      <td>194.289001</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_stamp  numberOfTaskIndex  numberOfMachineId  meanCPUUsage  \\\n",
       "0       600.0             3089.0             3089.0      0.668381   \n",
       "1       780.0             3090.0             3090.0      0.668381   \n",
       "2       960.0             3089.0             3089.0      0.739129   \n",
       "3      1140.0             3089.0             3089.0      0.739129   \n",
       "4      1320.0             3089.0             3089.0      0.558318   \n",
       "\n",
       "   canonical_memory_usage  AssignMem  unmapped_cache_usage  page_cache_usage  \\\n",
       "0                0.158746   0.351781              0.018816          0.030655   \n",
       "1                0.158746   0.351781              0.018816          0.030655   \n",
       "2                0.164337   0.360930              0.019065          0.032660   \n",
       "3                0.164337   0.360930              0.019065          0.032660   \n",
       "4                0.164920   0.362985              0.019132          0.033352   \n",
       "\n",
       "   max_mem_usage  mean_diskIO_time  mean_local_disk_space  max_cpu_usage  \\\n",
       "0       0.189231          0.006224               0.004191        5.33933   \n",
       "1       0.189231          0.006224               0.004191        5.33933   \n",
       "2       0.196537          0.002072               0.004189        5.17264   \n",
       "3       0.196537          0.002072               0.004189        5.17264   \n",
       "4       0.189972          0.000705               0.004188        4.69266   \n",
       "\n",
       "   max_disk_io_time         cpi       mai  sampling_portion  agg_type  \\\n",
       "0          0.761954  182.528000  0.388110               0.0    3089.0   \n",
       "1          0.761954  182.528000  0.388110               0.0    3090.0   \n",
       "2          0.336054  187.960999  0.396634               0.0    3089.0   \n",
       "3          0.336054  187.960999  0.396634               0.0    3089.0   \n",
       "4          0.093905  194.289001  0.424709               0.0    3089.0   \n",
       "\n",
       "   sampled_cpu_usage  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data_dir = '../data/google_trace_timeseries/'\n",
    "data_name = {'3': 'data_resource_usage_3Minutes_6176858948.csv',\n",
    "             '5': 'data_resource_usage_5Minutes_6176858948.csv',\n",
    "             '8': 'data_resource_usage_8Minutes_6176858948.csv',\n",
    "             '10': 'data_resource_usage_10Minutes_6176858948.csv'}\n",
    "col_names = ['time_stamp', 'numberOfTaskIndex', 'numberOfMachineId', \n",
    "             'meanCPUUsage', 'canonical_memory_usage', 'AssignMem',\n",
    "             'unmapped_cache_usage', 'page_cache_usage', 'max_mem_usage',\n",
    "             'mean_diskIO_time', 'mean_local_disk_space', 'max_cpu_usage',\n",
    "             'max_disk_io_time', 'cpi', 'mai', 'sampling_portion',\n",
    "             'agg_type', 'sampled_cpu_usage']\n",
    "\n",
    "dataset_3 = pd.read_csv(data_dir+data_name['3'], header=None, names=col_names)\n",
    "dataset_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9d2c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_3_compact = dataset_3.loc[:, ('meanCPUUsage', 'canonical_memory_usage', 'mean_diskIO_time', 'mean_local_disk_space')]\n",
    "dataset_3_compact.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13920,)\n",
      "(13920, 1)\n"
     ]
    }
   ],
   "source": [
    "data_cpu = dataset_3_compact.loc[:, 'meanCPUUsage']\n",
    "data_cpu.to_csv('cpu.csv', index=None)\n",
    "data_cpu = dataset_3_compact.loc[:,'meanCPUUsage'].values\n",
    "print(data_cpu.shape)\n",
    "data_cpu = data_cpu.reshape(data_cpu.shape[0],1)\n",
    "print(data_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)   var1(t)\n",
      "1   0.668381  0.668381\n",
      "2   0.668381  0.739129\n",
      "3   0.739129  0.739129\n",
      "4   0.739129  0.558318\n",
      "5   0.558318  0.539101\n"
     ]
    }
   ],
   "source": [
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    " \n",
    "data = series_to_supervised(data_cpu, 1, 1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2882b87e7e23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# crate dynamic RNN object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn_tuple_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "batch_size = 50\n",
    "num_steps = 4\n",
    "\n",
    "hidden_size = 100\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "# create LSTM network\n",
    "# set up the state storage / extraction\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, hidden_size])\n",
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], \n",
    "                                   state_per_layer_list[idx][1]) \n",
    "     for idx in range(num_layers)]\n",
    ")\n",
    "\n",
    "# create an LSTM cell to be unrolled\n",
    "cell = tf.contrib.rnn.LSTMCell(hidden_size, forget_bias=1.0)\n",
    "# add a dropout wrapper\n",
    "cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "# many layers\n",
    "layers = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)], state_is_tuple=True)\n",
    "\n",
    "# crate dynamic RNN object\n",
    "output, state = tf.nn.dynamic_rnn(layers, inputs, dtype=tf.float32, initial_state=rnn_tuple_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
