{
	"epochs": [100],
	"batch_size": [8, 16, 32, 64, 128, 256],
	"learning_rate":[0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3],
	"activation": ["relu", "sigmoid", "tanh"],
	"optimizer": ["adam", "rmsprop", "adagrad"],
	"layers": [[8, 8], [2, 2], [3, 3, 3]],
	"sliding": [1]
	
}